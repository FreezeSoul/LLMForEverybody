## 1. 什么是大模型的微调

大模型的微调（Fine-tuning），通常是指在已经预训练好的大型语言模型（Large Language Models，简称LLMs）基础上，使用特定的数据集进行进一步的训练，以使模型适应特定的任务或领域。这个过程可以让模型学习到特定领域的知识，优化其在特定NLP任务中的表现，比如情感分析、实体识别、文本分类、对话生成等。

1. **预训练模型**：在微调之前，大模型通常已经经过大量的无监督预训练，这使得模型掌握了语言的基本统计特征和知识，具备了预测下一个词的能力。

2. **任务特定的数据集**：微调时，会使用与特定任务相关的标注数据对模型进行训练。这些数据提供了模型需要学习的特定领域的信息。

3. **权重调整**：微调过程中，模型的权重会根据特定任务的数据进行调整。这可以是全量参数更新（Full Fine-tuning），也可以是参数高效微调（Parameter-Efficient Fine-Tuning，PEFT），后者只更新模型中的一部分参数。

## 2. PEFT（Parameter-Efficient Fine-Tuning）

与传统的微调方法相比，PEFT有效地降低了计算和内存需求，因为它只对模型参数的一小部分进行微调，同时冻结大部分预训练网络。这种策略减轻了大语言模型灾难性的遗忘，并显著降低了计算和存储成本。

PEFT的主要方法 见  Adapters 和 Soft prompts 的链接。

- 0

## 3. 框架

1. **huggingface/peft**[1](#refer-anchor-1)：huggingface开源的参数高效微调（Parameter-Efficient Fine-Tuning）基础工具；

- 1

2. **modelscope/ms-swift**[2](#refer-anchor-2)：modelscope开源的轻量级微调框架，以中文大模型为主，支持各类微调方法。可以通过执行脚本进行微调，也可以在代码环境中一键微调，自带微调数据集和验证数据集，可以一键微调+模型验证；

- 2

3. **hiyouga/LLaMA-Factory**[3](#refer-anchor-3)：一个全栈微调工具，支持海量模型+各种主流微调方法。它支持运行脚本微调、基于Web端微调，并自带基础训练数据集。除微调外，还支持增量预训练和全量微调；

- 3

4. **NVIDIA/Megatron-LM**[4](#refer-anchor-4)：NVIDIA开发的大模型训练框架，支持大规模的预训练和微调。适用于需要极高性能和规模的大模型训练和微调。

- 4

## 参考

<div id="refer-anchor-1"></div>

[1] [peft](https://huggingface.co/docs/peft/index)

<div id="refer-anchor-2"></div>

[2] [ms-swift](https://github.com/modelscope/ms-swift)

<div id="refer-anchor-3"></div>

[3] [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)

<div id="refer-anchor-4"></div>

[4] [Megatron-LM](https://github.com/NVIDIA/Megatron-LM)

## 欢迎关注我的GitHub和微信公众号[真-忒修斯之船]，来不及解释了，快上船！

[GitHub: LLMForEverybody](https://github.com/luhengshiwo/LLMForEverybody)

仓库上有原始的Markdown文件，完全开源，欢迎大家Star和Fork！